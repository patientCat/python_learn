{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luke/miniconda3/envs/demo/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/luke/miniconda3/envs/demo/lib/python3.8/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <870081F6-12FD-3CEA-BC5C-30F4764F2A98> /Users/luke/miniconda3/envs/demo/lib/python3.8/site-packages/torchvision/image.so\n",
      "  Expected in:     <F3CB84DE-97C1-34D2-AFB8-54D9DA60ADCD> /Users/luke/miniconda3/envs/demo/lib/python3.8/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from ModelToys import LinearModel\n",
    "from torch.utils.data import DataLoader\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T08:50:17.680112Z",
     "start_time": "2024-07-06T08:50:13.624134Z"
    }
   },
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-07-06T08:50:19.863285Z",
     "start_time": "2024-07-06T08:50:19.860423Z"
    }
   },
   "outputs": [],
   "source": [
    "#transforms.ToTensor(1)\n",
    "# TypeError: __init__() takes 1 positional argument but 3 were given\n",
    "# 注意看， ToTensor是一个class，__init__只接收一个参数。默认会把自己当作self传入，如果再传1，就是给了2个参数\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# 归一化， 0.1307, 0.3081 事先算好的均值和方差\n",
    "norm_transform = \\\n",
    "    transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "# prepare data\n",
    "train_data = datasets.MNIST(\"../data/\", train=True, transform=norm_transform, download=False)\n",
    "test_data_xy = datasets.MNIST(\"../data/\", train=False, transform=norm_transform, download=False)\n",
    "print(len(train_data))\n",
    "print(train_data[0])\n",
    "datasize = len(train_data)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "(tensor([[[-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.3860, -0.1951,\n",
      "          -0.1951, -0.1951,  1.1795,  1.3068,  1.8032, -0.0933,  1.6887,\n",
      "           2.8215,  2.7197,  1.1923, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.0424,  0.0340,  0.7722,  1.5359,  1.7396,  2.7960,\n",
      "           2.7960,  2.7960,  2.7960,  2.7960,  2.4396,  1.7650,  2.7960,\n",
      "           2.6560,  2.0578,  0.3904, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "           0.1995,  2.6051,  2.7960,  2.7960,  2.7960,  2.7960,  2.7960,\n",
      "           2.7960,  2.7960,  2.7960,  2.7706,  0.7595,  0.6195,  0.6195,\n",
      "           0.2886,  0.0722, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.1951,  2.3633,  2.7960,  2.7960,  2.7960,  2.7960,  2.7960,\n",
      "           2.0960,  1.8923,  2.7197,  2.6433, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242,  0.5940,  1.5614,  0.9377,  2.7960,  2.7960,  2.1851,\n",
      "          -0.2842, -0.4242,  0.1231,  1.5359, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.2460, -0.4115,  1.5359,  2.7960,  0.7213,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242,  1.3450,  2.7960,  1.9942,\n",
      "          -0.3988, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.2842,  1.9942,  2.7960,\n",
      "           0.4668, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.0213,  2.6433,\n",
      "           2.4396,  1.6123,  0.9504, -0.4115, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.6068,\n",
      "           2.6306,  2.7960,  2.7960,  1.0904, -0.1060, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "           0.1486,  1.9432,  2.7960,  2.7960,  1.4850, -0.0806, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.2206,  0.7595,  2.7833,  2.7960,  1.9560, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242,  2.7451,  2.7960,  2.7451,  0.3904,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "           0.1613,  1.2305,  1.9051,  2.7960,  2.7960,  2.2105, -0.3988,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.0722,  1.4596,\n",
      "           2.4906,  2.7960,  2.7960,  2.7960,  2.7578,  1.8923, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.1187,  1.0268,  2.3887,  2.7960,\n",
      "           2.7960,  2.7960,  2.7960,  2.1342,  0.5686, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.1315,  0.4159,  2.2869,  2.7960,  2.7960,  2.7960,\n",
      "           2.7960,  2.0960,  0.6068, -0.3988, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.1951,\n",
      "           1.7523,  2.3633,  2.7960,  2.7960,  2.7960,  2.7960,  2.0578,\n",
      "           0.5940, -0.3097, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242,  0.2758,  1.7650,  2.4524,\n",
      "           2.7960,  2.7960,  2.7960,  2.7960,  2.6815,  1.2686, -0.2842,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242,  1.3068,  2.7960,  2.7960,\n",
      "           2.7960,  2.2742,  1.2941,  1.2559, -0.2206, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242]]]), 5)\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T08:50:22.241160Z",
     "start_time": "2024-07-06T08:50:22.131569Z"
    }
   },
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data_shape=torch.Size([60000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# shape 60000 * 28 * 28\n",
    "print(f\"train_data_shape={train_data.data.shape}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-06T08:50:27.745635Z",
     "start_time": "2024-07-06T08:50:27.741506Z"
    }
   },
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "train_data_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "test_data_loader = DataLoader(dataset=test_data_xy, shuffle=True, num_workers=0)"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T08:50:38.078687Z",
     "start_time": "2024-07-06T08:50:38.074723Z"
    }
   },
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-07-06T08:50:41.208667Z",
     "start_time": "2024-07-06T08:50:41.200536Z"
    }
   },
   "outputs": [],
   "source": [
    "# build model\n",
    "model = LinearModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-07-06T08:50:43.712076Z",
     "start_time": "2024-07-06T08:50:42.791530Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luke/miniconda3/envs/demo/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "optim_f = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "loss_f = torch.nn.CrossEntropyLoss(size_average=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "x= torch.Size([500, 784])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luke/miniconda3/envs/demo/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/luke/miniconda3/envs/demo/lib/python3.8/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <870081F6-12FD-3CEA-BC5C-30F4764F2A98> /Users/luke/miniconda3/envs/demo/lib/python3.8/site-packages/torchvision/image.so\n",
      "  Expected in:     <F3CB84DE-97C1-34D2-AFB8-54D9DA60ADCD> /Users/luke/miniconda3/envs/demo/lib/python3.8/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/Users/luke/miniconda3/envs/demo/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/luke/miniconda3/envs/demo/lib/python3.8/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <870081F6-12FD-3CEA-BC5C-30F4764F2A98> /Users/luke/miniconda3/envs/demo/lib/python3.8/site-packages/torchvision/image.so\n",
      "  Expected in:     <F3CB84DE-97C1-34D2-AFB8-54D9DA60ADCD> /Users/luke/miniconda3/envs/demo/lib/python3.8/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/Users/luke/miniconda3/envs/demo/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/luke/miniconda3/envs/demo/lib/python3.8/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <870081F6-12FD-3CEA-BC5C-30F4764F2A98> /Users/luke/miniconda3/envs/demo/lib/python3.8/site-packages/torchvision/image.so\n",
      "  Expected in:     <F3CB84DE-97C1-34D2-AFB8-54D9DA60ADCD> /Users/luke/miniconda3/envs/demo/lib/python3.8/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/Users/luke/miniconda3/envs/demo/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/luke/miniconda3/envs/demo/lib/python3.8/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <870081F6-12FD-3CEA-BC5C-30F4764F2A98> /Users/luke/miniconda3/envs/demo/lib/python3.8/site-packages/torchvision/image.so\n",
      "  Expected in:     <F3CB84DE-97C1-34D2-AFB8-54D9DA60ADCD> /Users/luke/miniconda3/envs/demo/lib/python3.8/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 10)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 10\u001B[0m\n\u001B[1;32m      8\u001B[0m data \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m28\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m28\u001B[39m)\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx=\u001B[39m\u001B[38;5;124m\"\u001B[39m, data\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m---> 10\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m optim_f\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m     12\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_f(y_pred, target)\n",
      "File \u001B[0;32m~/python/learn_python/python_learn/machingLearning/pytorch/12_self_attention/ModelToys.py:25\u001B[0m, in \u001B[0;36mLinearModel.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     23\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mactiveF(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlinear4\u001B[38;5;241m.\u001B[39mforward(x))\n\u001B[1;32m     24\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mactiveF(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlinear5\u001B[38;5;241m.\u001B[39mforward(x))\n\u001B[0;32m---> 25\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msoftmax\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[0;32m~/miniconda3/envs/demo/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/demo/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/demo/lib/python3.8/site-packages/torch/nn/modules/activation.py:1514\u001B[0m, in \u001B[0;36mSoftmax.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m   1513\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m-> 1514\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msoftmax\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_stacklevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/demo/lib/python3.8/site-packages/torch/nn/functional.py:1858\u001B[0m, in \u001B[0;36msoftmax\u001B[0;34m(input, dim, _stacklevel, dtype)\u001B[0m\n\u001B[1;32m   1856\u001B[0m     dim \u001B[38;5;241m=\u001B[39m _get_softmax_dim(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msoftmax\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39mdim(), _stacklevel)\n\u001B[1;32m   1857\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1858\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43minput\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msoftmax\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdim\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1859\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1860\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39msoftmax(dim, dtype\u001B[38;5;241m=\u001B[39mdtype)\n",
      "\u001B[0;31mIndexError\u001B[0m: Dimension out of range (expected to be in range of [-2, 1], but got 10)"
     ]
    }
   ],
   "source": [
    "epoch = 200\n",
    "loss_history = []\n",
    "for i in range(epoch):\n",
    "    curr_loss = 0\n",
    "    for idx, data in enumerate(train_data_loader):\n",
    "        data, target = data\n",
    "        print(data.__class__)\n",
    "        data = data.view(-1, 28 * 28)\n",
    "        print(\"x=\", data.shape)\n",
    "        y_pred = model.forward(data)\n",
    "        optim_f.zero_grad()\n",
    "        loss = loss_f(y_pred, target)\n",
    "        curr_loss = loss.item()\n",
    "        loss.backward()\n",
    "        optim_f.step()\n",
    "        clear_output()\n",
    "    loss_history.append(curr_loss)\n",
    "\n"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T08:50:56.539361Z",
     "start_time": "2024-07-06T08:50:49.848752Z"
    }
   },
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "iteration = int(datasize / batch_size)\n",
    "\n",
    "x = np.linspace(1, epoch, epoch)\n",
    "print(loss_history)\n",
    "\n",
    "plt.plot(x, loss_history)"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T08:49:20.848511Z",
     "start_time": "2024-07-06T08:49:20.848401Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo",
   "language": "python",
   "name": "demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
